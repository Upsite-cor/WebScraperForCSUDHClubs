# WebScraperForCSUDHClubs
This project serves as an efficient web scraper, dedicated to extracting vital information from the HTML file sourced from https://torolink.csudh.edu/organizations. By harnessing its capabilities, you can effortlessly scrape club names and their corresponding hyperlinks. But that's not allâ€”this project goes the extra mile by creating a default response for an AI (called ask-teddy), leveraging the concatenated club names.

Contained within this repository are 1 Java file and 4 text files, each playing a crucial role in the project's functionality. The "about.txt" file holds the frequently asked questions about clubs, serving as a key component in creating the default response. It is expertly combined with the club names, forming a comprehensive answer for the AI.

The "clublinks.txt" file is home to the valuable links for each club, enabling easy access to further explore the club's details. Meanwhile, the "DefaultResponse.txt" file houses the desired response for the AI, ensuring a prompt and accurate answer.

Lastly, the "HelpertoCreate.txt" file contains the HTML structure from https://torolink.csudh.edu/organizations that the project utilizes to scrape all the necessary data. It acts as a guide, facilitating the seamless input of club information into "clublinks.txt" and the extraction of club names.

With this repository, you have the tools to effortlessly scrape club data from https://torolink.csudh.edu/organizations, generate default AI responses, and navigate the project's various files. Join us on this exciting journey of web scraping and data manipulation as we unlock valuable insights from the world of clubs.

**Note**: Please note that in order to ensure the proper functionality of this project, it may be necessary to adjust the file path. This modification is essential for seamless execution. However, rest assured that regardless of the adjustments required, this project is designed to be user-friendly and accessible to all. I aim to provide clear and concise instructions that will enable anyone to understand and utilize this web scraping solution effectively. 
